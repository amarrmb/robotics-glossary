---
title: DGX Spark
description: NVIDIA's desktop AI supercomputer for robotics development and simulation
sidebar:
  badge:
    text: Practical
    variant: success
last_validated: 2026-01-21
---

import { Aside, Card, CardGrid, LinkCard, Tabs, TabItem } from '@astrojs/starlight/components';

<span class="level-badge practical">Practical</span>

**DGX Spark** is NVIDIA's desktop-class AI supercomputer, announced at CES 2025. It brings datacenter AI performance to developers' desks, making it ideal for robotics development, simulation, and foundation model training without cloud dependencies.

<Aside type="tip" title="Availability">
DGX Spark became commercially available October 15, 2025. Founders Edition is $3,999 (4TB storage); partner versions start at $2,999 (1TB).
</Aside>

## Why DGX Spark for Robotics?

DGX Spark fills a critical gap in the robotics development workflow:

- **Train locally**: Fine-tune foundation models without cloud costs
- **Run Isaac Sim**: Full Omniverse simulation at your desk
- **Develop for Thor**: Same software stack as Jetson Thor deployment target
- **Air-gapped development**: No internet required for sensitive projects

## Specifications

| Spec | DGX Spark |
|------|-----------|
| GPU | NVIDIA GB10 Grace Blackwell Superchip |
| AI Performance | 1,000 TOPS (INT8), 1 PFLOP (FP4 sparse) |
| CUDA Cores | 6,144 |
| Tensor Cores | 192 (5th gen) |
| RT Cores | 48 (4th gen) |
| Memory | 128GB unified LPDDR5X |
| Memory Bandwidth | 273 GB/s |
| CPU | 20-core ARM (10x Cortex-X925 + 10x Cortex-A725) |
| Storage | 4TB NVMe (Founders), 1TB+ (partners) |
| Connectivity | 1x 10GbE, 2x QSFP (200Gbps), WiFi 7, BT 5.3, 4x USB 4.0 |
| Power | 240W PSU, 140W TDP |
| Dimensions | 150 × 150 × 50.5 mm (1.2 kg) |

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                      DGX Spark                               │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────┐   │
│  │           NVIDIA GB10 Grace Blackwell Superchip     │   │
│  │  ┌───────────────┐  ┌───────────────────────────┐  │   │
│  │  │ CUDA Cores    │  │ Transformer Engine        │  │   │
│  │  │ 6,144         │  │ FP4 / FP8 / BF16          │  │   │
│  │  └───────────────┘  └───────────────────────────┘  │   │
│  │  ┌───────────────┐  ┌───────────────────────────┐  │   │
│  │  │ Tensor Cores  │  │ RT Cores (Gen 4)          │  │   │
│  │  │ 192 (Gen 5)   │  │ 48 cores                  │  │   │
│  │  └───────────────┘  └───────────────────────────┘  │   │
│  └─────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         128GB Unified Memory (CPU + GPU)            │   │
│  └─────────────────────────────────────────────────────┘   │
│  ┌──────────────┐  ┌──────────────┐  ┌───────────────┐    │
│  │ ARM CPU      │  │ 4TB NVMe     │  │ 10GbE + QSFP  │    │
│  │ 20 cores     │  │ Storage      │  │ WiFi 7        │    │
│  └──────────────┘  └──────────────┘  └───────────────┘    │
└─────────────────────────────────────────────────────────────┘
```

## Robotics Development Workflow

<CardGrid>
  <Card title="1. Simulate" icon="laptop">
    Run Isaac Sim locally with full ray-tracing. Create digital twins of your robots and environments.
  </Card>
  <Card title="2. Train" icon="rocket">
    Fine-tune foundation models (GR00T, VLA) on your own data without cloud uploads.
  </Card>
  <Card title="3. Validate" icon="approve-check">
    Test perception and control stacks in simulation before real hardware.
  </Card>
  <Card title="4. Deploy" icon="right-arrow">
    Export to Jetson Thor/Orin with identical software stack.
  </Card>
</CardGrid>

## Software Stack

DGX Spark runs the same software as NVIDIA's datacenter DGX systems:

```
┌─────────────────────────────────────────────────────────────┐
│                   Your Development                           │
├─────────────────────────────────────────────────────────────┤
│  Isaac Sim 5.x │ Isaac Lab │ Omniverse Kit │ USD Composer   │
├─────────────────────────────────────────────────────────────┤
│  PyTorch 2.9 │ TensorRT │ Triton │ NeMo │ cuML │ RAPIDS    │
├─────────────────────────────────────────────────────────────┤
│  CUDA 13 │ cuDNN │ Transformer Engine │ NCCL               │
├─────────────────────────────────────────────────────────────┤
│             DGX OS (Ubuntu 24.04, HWE kernel 6.14)          │
└─────────────────────────────────────────────────────────────┘
```

<Tabs>
  <TabItem label="Isaac Sim">
    ```bash
    # Isaac Sim 5.x runs natively on DGX Spark
    # Full ray-tracing, PhysX 5, domain randomization

    # Launch Isaac Sim
    ~/.local/share/ov/pkg/isaac-sim-5.1.0/isaac-sim.sh

    # Or via Omniverse Launcher
    omniverse-launcher
    ```

    DGX Spark can run complex warehouse scenes at 30+ FPS with ray-tracing enabled.

    Note: Some Isaac Lab features are not supported on aarch64: SkillGen, OpenXR, SKRL/JAX training.
  </TabItem>
  <TabItem label="Foundation Models">
    ```python
    # Fine-tune GR00T or custom VLA models locally
    import torch
    from nemo.collections.multimodal import VLAModel

    # Load base model (fits in 128GB unified memory)
    model = VLAModel.from_pretrained("nvidia/gr00t-base")

    # Fine-tune on your robot's data
    trainer = Trainer(
        accelerator="gpu",
        precision="bf16-mixed",
        max_epochs=10,
    )
    trainer.fit(model, your_dataloader)

    # Export for Jetson Thor
    model.export("robot_policy.onnx", target="jetson-thor")
    ```
  </TabItem>
  <TabItem label="Isaac Lab">
    ```python
    # Reinforcement learning for robotics
    from omni.isaac.lab import SimulationApp
    from omni.isaac.lab_tasks.manager_based import ManagerBasedRLEnv

    # DGX Spark can run 4096+ parallel environments
    app = SimulationApp({"headless": False})

    env = ManagerBasedRLEnv(
        cfg=my_robot_cfg,
        num_envs=4096,  # Massive parallelism
    )

    # Train with stable-baselines3 or rl_games
    from stable_baselines3 import PPO
    model = PPO("MlpPolicy", env, verbose=1)
    model.learn(total_timesteps=10_000_000)
    ```
  </TabItem>
</Tabs>

## Use Cases

### Local Foundation Model Development

```python
# Train a 7B parameter VLA model entirely on DGX Spark
# 128GB unified memory eliminates GPU memory constraints

from transformers import AutoModelForVision2Seq

# Load large model - fits in unified memory
model = AutoModelForVision2Seq.from_pretrained(
    "nvidia/gr00t-7b",
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

# Fine-tune on robot demonstration data
trainer = Trainer(
    model=model,
    train_dataset=robot_demos,
    args=TrainingArguments(
        bf16=True,
        per_device_train_batch_size=8,  # Large batches possible
        gradient_accumulation_steps=4,
    ),
)
trainer.train()
```

### High-Fidelity Simulation

Run photorealistic simulations for:
- Synthetic data generation with domain randomization
- Sim-to-real transfer validation
- Digital twin verification
- Multi-robot coordination testing

### Edge Deployment Testing

```bash
# Simulate Jetson Thor performance on DGX Spark
# Use power/performance profiles

nvidia-smi --power-limit=150  # Match Thor power envelope
# Run same JetPack 7.0 containers as production
docker run --gpus all nvcr.io/nvidia/jetson-thor:jp7.0-runtime
```

## DGX Spark vs Alternatives

| Aspect | DGX Spark | Gaming PC | Cloud GPU | DGX Station |
|--------|-----------|-----------|-----------|-------------|
| Price | $2,999+ | $2,000+ | $/hour | $50,000+ |
| AI TOPS | 1,000 | ~300 | Varies | 2,000+ |
| Unified Memory | 128GB | 16-24GB | 80GB (A100) | 256GB+ |
| Isaac Sim | Full | Limited | Network latency | Full |
| Transformer Engine | Yes | No | Yes (H100) | Yes |
| Form Factor | NUC-style | Tower | N/A | Workstation |
| Air-gapped | Yes | Yes | No | Yes |

## Getting Started

### 1. Unbox and Connect

- Connect power (240W adapter included)
- Connect display via HDMI 2.1a or USB 4.0
- Connect to network (10GbE or QSFP recommended for large datasets)

### 2. Initial Setup

```bash
# DGX Spark comes with DGX OS pre-installed
# On first boot, create user account

# Verify GPU
nvidia-smi

# Check Transformer Engine
python -c "import transformer_engine; print(transformer_engine.__version__)"
```

### 3. Install Robotics Stack

```bash
# Install Isaac Sim via Omniverse Launcher
# Or command line:
./omniverse-launcher-linux.AppImage

# Install Isaac Lab
pip install omni-isaac-lab

# Install Isaac ROS development tools
sudo apt install ros-jazzy-isaac-ros-dev-tools
```

## Related Terms

<CardGrid>
  <LinkCard
    title="Jetson Thor"
    description="Edge deployment target for DGX Spark development"
    href="/robotics-glossary/hardware/compute/jetson-thor/"
  />
  <LinkCard
    title="Isaac Sim"
    description="Omniverse-based robotics simulation"
    href="/robotics-glossary/software/simulation/isaac-sim/"
  />
  <LinkCard
    title="Jetson Orin"
    description="Cost-effective edge deployment option"
    href="/robotics-glossary/hardware/compute/jetson-orin/"
  />
</CardGrid>

## Sources

- [NVIDIA DGX Spark Official](https://www.nvidia.com/en-us/products/workstations/dgx-spark/) — Core specifications and product overview
- [NVIDIA DGX Spark Hardware Docs](https://docs.nvidia.com/dgx/dgx-spark/hardware.html) — Detailed hardware specifications, connectivity, dimensions
- [NVIDIA Marketplace](https://marketplace.nvidia.com/en-us/enterprise/personal-ai-supercomputers/dgx-spark/) — Pricing and availability
- [NVIDIA Newsroom](https://nvidianews.nvidia.com/news/nvidia-dgx-spark-arrives-for-worlds-ai-developers) — Launch announcement (Oct 2025)
- [NVIDIA Developer Blog - CES 2026](https://developer.nvidia.com/blog/new-software-and-model-optimizations-supercharge-nvidia-dgx-spark/) — Software optimizations achieving 2.5× performance gains
- [DGX Spark Release Notes](https://docs.nvidia.com/dgx/dgx-spark/release-notes.html) — DGX OS 7.3.1, CUDA 13.0.2, Driver 580.95.05
- [Isaac Sim Requirements](https://docs.isaacsim.omniverse.nvidia.com/5.1.0/installation/requirements.html) — Isaac Sim 5.x compatibility and aarch64 limitations
- [WCCFTech GB10 Details](https://wccftech.com/nvidia-gb10-superchip-soc-3nm-20-arm-v9-2-cpu-cores-nvfp4-blackwell-gpu-lpddr5x-9400-memory-140w-tdp/) — CPU architecture details
- [VideoCardz](https://videocardz.com/newz/nvidia-dgx-spark-features-6144-cuda-cores-just-as-many-as-rtx-5070) — CUDA core count confirmation
